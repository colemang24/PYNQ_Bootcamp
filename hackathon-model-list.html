<!doctype html>
<html>

<head>
  <title>PYNQ Bootcamp</title>
  <meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1">
  <link href="https://use.fontawesome.com/releases/v5.2.0/css/all.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/frame.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/controls.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/custom.css" media="screen" rel="stylesheet" type="text/css" />
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel="stylesheet">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="js/menu.js"></script>
  <script src="js/footer.js"></script>
  <style>
    .menu-index {
      color: rgb(255, 255, 255) !important;
      opacity: 1 !important;
      font-weight: 700 !important;
    }
  </style>
</head>

<body>
  <div class="menu-container"></div>
  <div class="content-container">
    <div class="content">
      <div class="content-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h1>Model List</h1>
            <hr>
            <p class="text">
              These are all of the pre trained models that will be avaliable for the bootcamp 
              with instructions on how to get them working on the board. The models are divided 
              by type. 
            </p>


            <h2>Classification</h2>
            <hr> 
            <p class="text">
              Identifies patterns in input data and categorizes into specific classes. 
            </p>

            
            <h2>Segmentation</h2>
            <hr>
            <p class="text">
              Divides input images or data into meaningful segments or regions. 
            </p>
            

            <h2>Natural language Processing (NLP)</h2>
            <hr> 
            <p class="text">
              Processes and interperates human language to produce natural language responses.. 
            </p>

            <h2>Text-OCR (Optical Character Recognition)</h2>
            <hr>
            <p class="text">
              Converts images of printed or hand written text into text that the computer can understand. 
            </p>
            <h2>Surveillance</h2>
            <hr>
            <p class="text">
              Used for general surveillance. Includes object detection, activity detetction, facial recognition and crowd monitoring.
            </p>

            <table width="786">
              <tbody>
              <tr>
              <td width="162">Model Name</td>
              <td width="300">Task</td>
              <td width="162">Description</td>
              <td width="162">Framework</td>
              </tr>
              <tr>
              <td width="162">tf2_resnet50_imagenet_224_224_7.76G_2.5</td>
              <td width="300">Object detection</td>
              <td width="162">Classifies various objects</td>
              <td width="162">TensorFlow</td>
              </tr>
              <tr>
              <td width="162">pt_vehicle-type-classification_CompCars_224_224_3.63G_2.5</td>
              <td width="300">Classification</td>
              <td width="162">Images of cars and car parts with labels and bounding boxes added</td>
              <td width="162">PyTorch</td>
              </tr>
              <tr>
              <td width="162">pt_OFA-rcan_DIV2K_360_640_45.7G_2.5</td>
              <td width="300">Surveillance</td>
              <td width="162">RCAN image super-resolution</td>
              <td width="162">Pytorch</td>
              </tr>
              <tr>
              <td width="162">pt_face-mask-detection_3.5</td>
              <td width="300">Surveillance</td>
              <td width="162">Real-time video streaming mask detection</td>
              <td width="162">Pytorch</td>
              </tr>
              <tr>
              <td width="162">pt_ENet_cityscapes_512_1024_11.3G_3.0</td>
              <td width="300">Segmentation</td>
              <td width="162">Segmentation for cityscapes</td>
              <td width="162">Pytorch</td>
              </tr>
              <tr>
              <td width="162">pt_BCC_shanghaitech_800_1000_268.9G_2.5</td>
              <td width="300">Surveillance</td>
              <td width="162">Couting number of people in corwds</td>
              <td width="162">Pytorch</td>
              </tr>
              <tr>
              <td width="162">tf_yolov3_voc_416_416_65.63G_2.5</td>
              <td width="300">Object Detection</td>
              <td width="162">Real tiem object detection</td>
              <td width="162">TensorFlow</td>
              </tr>
              <tr>
              <td width="162">pt_movenet_coco_192_192_0.5G_2.5</td>
              <td width="300">Surveillance</td>
              <td width="162">Pose detection</td>
              <td width="162">Pytorch</td>
              </tr>
              <tr>
              <td width="162">vehicle_type_resnet18_pt&nbsp;</td>
              <td width="300">Classification</td>
              <td width="162">Identifies car types</td>
              <td width="162">Pytorch</td>
              </tr>
              <tr>
              <td width="162">cf_plate-detection_320_320_0.49G_2.5</td>
              <td width="300">Detection</td>
              <td width="162">License Plate detetcion</td>
              <td width="162">Cafe&nbsp;</td>
              </tr>
              <tr>
              <td width="162">cf_refinedet_coco_360_480_0.8_25G_2.5</td>
              <td width="300">Detection</td>
              <td width="162">Pedestrian Detectto</td>
              <td width="162">Cafe&nbsp;</td>
              </tr>
              </tbody>
              </table>
        
        

            <h2>How to Upload and use a New Model</h2>
            <hr>
            <ol>
              <li>Access the Vitis AI Model Zoo (2.5 Branch) <a href="https://github.com/Xilinx/Vitis-AI/tree/2.5/model_zoo/model-list">(Click Here!)</a> </li>
              <li>Select the Model that you want and open it up in the github</li>
                <ul>
                  <li>For example you may want this model: tf_mlperf_resnet34_coco_1200_1200_433G_2.5</li>
                </ul>
              <li> Open {Model-Name}.yaml</li>
                <ul>
                  <li>after opening the file you will see a page with information on the model. 
                    Find the line with {Board: KV260} below this line there is a URI ending in {.tar.gz} </li>
                </ul>
              <li> After finding the link open your Terminal on your board and download the file</li>
              <ul>
                <li>Use the command below to download the file to your current directory</li>
                <li>wget {link from previous step} </li>
              </ul>
              <li> After downloading the file</li>
              <ul>
                <li>In your DIR you should see 2 new files, open the file with the same name as the model. 
                  Inside of this DIR there should be a .xmodel file with more files with information</li>
              
              </ul>
              <li>Take this .xmodel file and put it in the same directory as your .ipynb notebook file on your board</li>
          </ol>
          </div>
        </div>
      </div>
    </div>
  </div>
  <div class="footer-container"></div>
</body>

</html>